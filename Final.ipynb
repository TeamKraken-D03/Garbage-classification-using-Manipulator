{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel coordinates extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle click event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicked at: (504, 151)\n",
      "Clicked at: (420, 107)\n",
      "Clicked at: (319, 111)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(0)\n",
    "pixel_coordinates = []\n",
    "\n",
    "# Track mouse clicks\n",
    "def click_event(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        pixel_coordinates.append((x, y))\n",
    "        print(f\"Clicked at: ({x}, {y})\")\n",
    "\n",
    "cv2.namedWindow(\"Pixel Coordinates\")\n",
    "cv2.setMouseCallback(\"Pixel Coordinates\", click_event)\n",
    "\n",
    "# Display video feed\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Pixel Coordinates\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate homgeneous transform matrix for transformation from camera's frame of reference to end effector frame of reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homography Matrix: [[-1.21974072e+00 -4.47658707e-02  6.45627843e+02]\n",
      " [-9.80664918e-02  1.32604981e+00 -1.20234612e+02]\n",
      " [ 1.60982444e-04  2.56874582e-04  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Clicked at: (239, 115)\n",
    "# Clicked at: (376, 126)\n",
    "# Clicked at: (303, 189)a\n",
    "# Clicked at: (285, 199)\n",
    "# Clicked at: (226, 250)\n",
    "# Clicked at: (367, 260)\n",
    "\n",
    "pixel_coordinates = [[238, 115], [376, 125], [300, 190], [286, 200], [226, 247], [367, 261]]\n",
    "robot_coordinates = [[328.1, 8.5], [165.6, 8.5], [246.5, 90.9], [263.8, 107.5], [325.6, 168.8], [165.6, 168.8]]\n",
    "pixel_points = np.array(pixel_coordinates, dtype=np.float32)\n",
    "robot_points = np.array(robot_coordinates, dtype=np.float32)\n",
    "\n",
    "homography_matrix, _ = cv2.findHomography(pixel_points, robot_points)\n",
    "print(\"Homography Matrix:\", homography_matrix)\n",
    "\n",
    "def pixel_to_robot(x, y, matrix):\n",
    "    pixel = np.array([x, y, 1]).reshape(3, 1)\n",
    "    robot_coords = np.dot(matrix, pixel)\n",
    "    robot_coords /= robot_coords[2]  \n",
    "    return robot_coords[0][0], robot_coords[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box coordinates from camera reference to end effector reference frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = pixel_to_robot(280, 399, homography_matrix)\n",
    "box_x, box_y = box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBOT_IP: 192.168.1.155, VERSION: v2.2.0, PROTOCOL: V1, DETAIL: 6,9,LI1006,DL1000,v2.2.0, TYPE1300: [0, 0]\n",
      "change protocol identifier to 3\n",
      "ControllerError, code: 2\n",
      "[motion_enable], xArm is not ready to move\n",
      "[set_state], xArm is ready to move\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ControllerError had clean\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ControllerError, code: 2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from xarm.wrapper import XArmAPI\n",
    "\n",
    "\n",
    "arm = XArmAPI('192.168.1.155')\n",
    "arm.motion_enable(enable=True)\n",
    "arm.set_mode(0)\n",
    "arm.set_state(0)\n",
    "arm.connect()\n",
    "arm.move_gohome()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start window listener stream\n",
    "1. Click object to pick\n",
    "2. Transform pixel to end effector coordinate frame (P)\n",
    "3. Move arm to the point (P) with a fixed height\n",
    "4. Pick the object\n",
    "5. Go to dropping destination\n",
    "6. Lower arm and drop the object\n",
    "7. Go back to home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick up and drop sub-routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_coordinates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_up_and_drop(x_robot, y_robot):\n",
    "    arm.set_position(x_robot, y_robot, 70, speed=100)  \n",
    "    arm.set_position(x_robot, y_robot, 27, speed=100)  \n",
    "    arm.set_suction_cup(False)\n",
    "    arm.set_position(box_x, box_y, 200, speed=100)\n",
    "    arm.set_position(box_x, box_y, 100, speed=100)\n",
    "    arm.set_suction_cup(True)\n",
    "    arm.set_position(box_x, box_y, 200, speed=100)\n",
    "    arm.move_gohome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicked at: (365, 260)\n",
      "Moving to: (167.72602544189203, 167.69112189774935)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "cv2.namedWindow(\"Click to Move\")\n",
    "cv2.setMouseCallback(\"Click to Move\", click_event)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imshow(\"Click to Move\", frame)\n",
    "    \n",
    "    if len(pixel_coordinates) > 0:\n",
    "        x_pixel, y_pixel = pixel_coordinates.pop(0)\n",
    "        x_robot, y_robot = pixel_to_robot(x_pixel, y_pixel, homography_matrix)\n",
    "        print(f\"Moving to: ({x_robot}, {y_robot})\")\n",
    "        pick_up_and_drop(x_robot, y_robot)\n",
    "        # arm.set_position(x_robot, y_robot, 70, speed=100)  \n",
    "        # arm.set_position(x_robot, y_robot, 27, speed=100)  \n",
    "        # arm.set_suction_cup(False)\n",
    "        # arm.set_position(box_x, box_y, 200, speed=100)\n",
    "        # arm.set_position(box_x, box_y, 100, speed=100)\n",
    "        # arm.set_suction_cup(True)\n",
    "        # arm.set_position(box_x, box_y, 200, speed=100)\n",
    "        # arm.move_gohome()\n",
    "        \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the bounding box detections:\n",
      "```json\n",
      "[\n",
      "  {\"box_2d\": [434, 392, 490, 507], \"label\": \"cube\"},\n",
      "  {\"box_2d\": [341, 535, 407, 682], \"label\": \"cube\"},\n",
      "  {\"box_2d\": [277, 314, 351, 453], \"label\": \"cube\"},\n",
      "  {\"box_2d\": [426, 117, 492, 257], \"label\": \"cube\"},\n",
      "  {\"box_2d\": [556, 264, 610, 375], \"label\": \"cube\"},\n",
      "  {\"box_2d\": [589, 610, 657, 746], \"label\": \"cube\"},\n",
      "  {\"box_2d\": [471, 757, 534, 903], \"label\": \"cube\"}\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "import os\n",
    "from google import genai\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "prompt = (\n",
    "  \"Detect items, with no more than 20 items. Output a json list where each entry contains the 2D bounding box in box_2d and a text label in label.\"\n",
    ")\n",
    "\n",
    "img_path = \"imgs/WhatsApp Image 2025-03-05 at 16.53.00_17d1376b.jpg\"\n",
    "\n",
    "file_ref = client.files.upload(file=img_path)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "  model=\"gemini-2.0-flash\",\n",
    "  contents=[file_ref, prompt]\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate gemini api and the pickup and drop sub-routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "cv2.namedWindow(\"Click to Move\")\n",
    "cv2.setMouseCallback(\"Click to Move\", click_event)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imshow(\"Click to Move\", frame)\n",
    "\n",
    "    cv2.imwrite(\"imgs/captured_frame.jpg\", frame)\n",
    "    \n",
    "    # if len(pixel_coordinates) > 0:\n",
    "    #     x_pixel, y_pixel = pixel_coordinates.pop(0)\n",
    "    #     x_robot, y_robot = pixel_to_robot(x_pixel, y_pixel, homography_matrix)\n",
    "    #     print(f\"Moving to: ({x_robot}, {y_robot})\")\n",
    "    #     pick_up_and_drop(x_robot, y_robot)\n",
    "    #     # arm.set_position(x_robot, y_robot, 70, speed=100)  \n",
    "    #     # arm.set_position(x_robot, y_robot, 27, speed=100)  \n",
    "    #     # arm.set_suction_cup(False)\n",
    "    #     # arm.set_position(box_x, box_y, 200, speed=100)\n",
    "    #     # arm.set_position(box_x, box_y, 100, speed=100)\n",
    "    #     # arm.set_suction_cup(True)\n",
    "    #     # arm.set_position(box_x, box_y, 200, speed=100)\n",
    "    #     # arm.move_gohome()\n",
    "        \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
