{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel coordinates extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle click event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_coordinates = []\n",
    "\n",
    "# Track mouse clicks\n",
    "def click_event(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        pixel_coordinates.append((x, y))\n",
    "        print(f\"Clicked at: ({x}, {y})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(0)\n",
    "pixel_coordinates = []\n",
    "\n",
    "# Track mouse clicks\n",
    "def click_event(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        pixel_coordinates.append((x, y))\n",
    "        print(f\"Clicked at: ({x}, {y})\")\n",
    "\n",
    "cv2.namedWindow(\"Pixel Coordinates\")\n",
    "cv2.setMouseCallback(\"Pixel Coordinates\", click_event)\n",
    "\n",
    "# Display video feed\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Pixel Coordinates\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate homgeneous transform matrix for transformation from camera's frame of reference to end effector frame of reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homography Matrix: [[-1.12652760e+00  3.40585199e-02  6.19708826e+02]\n",
      " [ 2.72743826e-02  1.15644498e+00 -9.04650194e+01]\n",
      " [ 6.52525716e-05  5.57229232e-05  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "pixel_coordinates = [[197,32], [328,43], [256,83], [402,77], [231,137], [331,153], [316,166], [260,224], [405,220], [245,265], [333,260]]\n",
    "robot_coordinates = [[393.6,-47.6], [245.8,-29.9], [325.3,11.4], [164.9,7.9], [356.9,73.4], [244.5,92.9], [262.6,107.8], [323.9,170.4], [164.6,168.5], [343.1,215.1], [243.9,212.2]]\n",
    "pixel_points = np.array(pixel_coordinates, dtype=np.float32)\n",
    "robot_points = np.array(robot_coordinates, dtype=np.float32)\n",
    "\n",
    "homography_matrix, _ = cv2.findHomography(pixel_points, robot_points)\n",
    "print(\"Homography Matrix:\", homography_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_to_robot(x, y, matrix):\n",
    "    pixel = np.array([x, y, 1]).reshape(3, 1)\n",
    "    robot_coords = np.dot(matrix, pixel)\n",
    "    robot_coords /= robot_coords[2]  \n",
    "    return robot_coords[0][0], robot_coords[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box coordinates from camera reference to end effector reference frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = pixel_to_robot(306, 303, homography_matrix)\n",
    "box_x, box_y = box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK_VERSION: 1.14.8\n",
      "ROBOT_IP: 192.168.1.155, VERSION: v2.2.0, PROTOCOL: V1, DETAIL: 6,9,LI1006,DL1000,v2.2.0, TYPE1300: [0, 0]\n",
      "change protocol identifier to 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from xarm.wrapper import XArmAPI\n",
    "\n",
    "\n",
    "arm = XArmAPI('192.168.1.155')\n",
    "arm.motion_enable(enable=True)\n",
    "arm.set_mode(0)\n",
    "arm.set_state(0)\n",
    "arm.connect()\n",
    "arm.move_gohome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start window listener stream\n",
    "1. Click object to pick\n",
    "2. Transform pixel to end effector coordinate frame (P)\n",
    "3. Move arm to the point (P) with a fixed height\n",
    "4. Pick the object\n",
    "5. Go to dropping destination\n",
    "6. Lower arm and drop the object\n",
    "7. Go back to home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick up and drop sub-routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_coordinates = [] # Reinitialize pixel coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def pick_up_and_drop(x_robot, y_robot):\n",
    "    arm.set_position(x_robot, y_robot, 70)  \n",
    "    arm.set_position(x_robot, y_robot, 17, wait=True)  \n",
    "    arm.set_suction_cup(False)\n",
    "    time.sleep(1)\n",
    "    arm.set_position(x_robot, y_robot, 16.5, wait=True)  \n",
    "    arm.set_position(x_robot, y_robot, 70, wait=True)  \n",
    "    arm.set_position(box_x, box_y, 200)\n",
    "    arm.set_position(box_x, box_y, 100)\n",
    "    arm.set_suction_cup(True)\n",
    "    arm.set_position(box_x, box_y, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main pick up routine\n",
    "1. Start stream\n",
    "2. User selects object\n",
    "3. Arm moves and places it's end effector over the center of the object\n",
    "4. Arm lowers and picks up the object\n",
    "5. Arm goes to box location\n",
    "6. Arm drops the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicked at: (257, 157)\n",
      "Moving to: (327.1890762621443, 95.66513696902115)\n",
      "Clicked at: (260, 165)\n",
      "Moving to: (323.956617351429, 104.70077500758353)\n",
      "Clicked at: (239, 201)\n",
      "Moving to: (347.9898703731883, 144.62370994077784)\n",
      "Clicked at: (232, 122)\n",
      "Moving to: (354.7279688698958, 55.72646526077061)\n",
      "Clicked at: (252, 151)\n",
      "Moving to: (332.6965994095523, 88.82336310257618)\n",
      "Clicked at: (248, 144)\n",
      "Moving to: (337.07492422482045, 80.86951765030584)\n",
      "Clicked at: (176, 96)\n",
      "Moving to: (417.6784492829194, 24.934250731439587)\n",
      "Clicked at: (276, 95)\n",
      "Moving to: (304.9171657381117, 26.311828789104666)\n",
      "Clicked at: (196, 185)\n",
      "Moving to: (396.06190836446785, 125.91467334432974)\n",
      "Clicked at: (348, 147)\n",
      "Moving to: (225.7095868363908, 86.35556337292725)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "cv2.namedWindow(\"Click to Move\")\n",
    "cv2.setMouseCallback(\"Click to Move\", click_event)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imshow(\"Click to Move\", frame)\n",
    "    \n",
    "    if len(pixel_coordinates) > 0:\n",
    "        x_pixel, y_pixel = pixel_coordinates.pop(0)\n",
    "        x_robot, y_robot = pixel_to_robot(x_pixel, y_pixel, homography_matrix)\n",
    "        print(f\"Moving to: ({x_robot}, {y_robot})\")\n",
    "        pick_up_and_drop(x_robot, y_robot)\n",
    "        # arm.set_position(x_robot, y_robot, 70, speed=100)  \n",
    "        # arm.set_position(x_robot, y_robot, 27, speed=100)  \n",
    "        # arm.set_suction_cup(False)\n",
    "        # arm.set_position(box_x, box_y, 200, speed=100)\n",
    "        # arm.set_position(box_x, box_y, 100, speed=100)\n",
    "        # arm.set_suction_cup(True)\n",
    "        # arm.set_position(box_x, box_y, 200, speed=100)\n",
    "        # arm.move_gohome()\n",
    "        \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as captured_image.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame. Exiting...\")\n",
    "        break\n",
    "\n",
    "    cv2.imshow('Webcam Preview - Press Q to capture', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.imwrite('captured_image.jpg', frame)\n",
    "        print(\"Image saved as captured_image.jpg\")\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "model_name = \"gemini-2.0-flash\" \n",
    "\n",
    "bounding_box_system_instructions = \"\"\"\n",
    "    Return bounding boxes as a JSON array with labels. Never return masks or code fencing. Limit to 25 objects.\n",
    "    If an object is present multiple times, name them according to their unique characteristic (colors, size, position, unique characteristics, etc..).\n",
    "    \"\"\"\n",
    "\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_settings = [\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        threshold=\"BLOCK_ONLY_HIGH\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import io\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from PIL import ImageColor\n",
    "\n",
    "additional_colors = [colorname for (colorname, colorcode) in ImageColor.colormap.items()]\n",
    "\n",
    "def plot_bounding_boxes(im, bounding_boxes):\n",
    "    \"\"\"\n",
    "    Plots bounding boxes on an image with markers for each a name, using PIL, normalized coordinates, and different colors.\n",
    "\n",
    "    Args:\n",
    "        img_path: The path to the image file.\n",
    "        bounding_boxes: A list of bounding boxes containing the name of the object\n",
    "         and their positions in normalized [y1 x1 y2 x2] format.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the image\n",
    "    img = im\n",
    "    width, height = img.size\n",
    "    print(img.size)\n",
    "    # Create a drawing object\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # Define a list of colors\n",
    "    colors = [\n",
    "    'red',\n",
    "    'green',\n",
    "    'blue',\n",
    "    'yellow',\n",
    "    'orange',\n",
    "    'pink',\n",
    "    'purple',\n",
    "    'brown',\n",
    "    'gray',\n",
    "    'beige',\n",
    "    'turquoise',\n",
    "    'cyan',\n",
    "    'magenta',\n",
    "    'lime',\n",
    "    'navy',\n",
    "    'maroon',\n",
    "    'teal',\n",
    "    'olive',\n",
    "    'coral',\n",
    "    'lavender',\n",
    "    'violet',\n",
    "    'gold',\n",
    "    'silver',\n",
    "    ] + additional_colors\n",
    "\n",
    "    # Parsing out the markdown fencing\n",
    "    bounding_boxes = parse_json(bounding_boxes)\n",
    "\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "    # Iterate over the bounding boxes\n",
    "    for i, bounding_box in enumerate(json.loads(bounding_boxes)):\n",
    "      # Select a color from the list\n",
    "      color = colors[i % len(colors)]\n",
    "\n",
    "      # Convert normalized coordinates to absolute coordinates\n",
    "      abs_y1 = int(bounding_box[\"box_2d\"][0]/1000 * height)\n",
    "      abs_x1 = int(bounding_box[\"box_2d\"][1]/1000 * width)\n",
    "      abs_y2 = int(bounding_box[\"box_2d\"][2]/1000 * height)\n",
    "      abs_x2 = int(bounding_box[\"box_2d\"][3]/1000 * width)\n",
    "\n",
    "      if abs_x1 > abs_x2:\n",
    "        abs_x1, abs_x2 = abs_x2, abs_x1\n",
    "\n",
    "      if abs_y1 > abs_y2:\n",
    "        abs_y1, abs_y2 = abs_y2, abs_y1\n",
    "\n",
    "      # Draw the bounding box\n",
    "      draw.rectangle(\n",
    "          ((abs_x1, abs_y1), (abs_x2, abs_y2)), outline=color, width=4\n",
    "      )\n",
    "\n",
    "      # Draw the text\n",
    "      if \"label\" in bounding_box:\n",
    "        draw.text((abs_x1 + 8, abs_y1 + 6), bounding_box[\"label\"], fill=color, font=font)\n",
    "\n",
    "    # Display the image\n",
    "    img.save(\"output_image.jpg\")  # or \"output_image.png\"\n",
    "    print(\"Image saved as output_image.jpg\")\n",
    "\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(json_output):\n",
    "    # Parsing out the markdown fencing\n",
    "    lines = json_output.splitlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        if line == \"```json\":\n",
    "            json_output = \"\\n\".join(lines[i+1:])  # Remove everything before \"```json\"\n",
    "            json_output = json_output.split(\"```\")[0]  # Remove everything after the closing \"```\"\n",
    "            break  # Exit the loop once \"```json\" is found\n",
    "    return json_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "  {\"box_2d\": [237, 390, 300, 436], \"label\": \"green cube\"},\n",
      "  {\"box_2d\": [193, 488, 262, 535], \"label\": \"green cube\"},\n",
      "  {\"box_2d\": [368, 415, 425, 458], \"label\": \"red cube\"},\n",
      "  {\"box_2d\": [270, 548, 331, 593], \"label\": \"green cube\"},\n",
      "  {\"box_2d\": [275, 301, 343, 355], \"label\": \"blue cube\"},\n",
      "  {\"box_2d\": [268, 488, 331, 530], \"label\": \"yellow cube\"},\n",
      "  {\"box_2d\": [335, 470, 402, 520], \"label\": \"green cube\"},\n",
      "  {\"box_2d\": [231, 435, 306, 490], \"label\": \"blue cube\"},\n",
      "  {\"box_2d\": [295, 403, 362, 455], \"label\": \"red cube\"},\n",
      "  {\"box_2d\": [418, 498, 487, 548], \"label\": \"green cube\"}\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Detect the 2d bounding boxes of the small cubes (with “label” as topping description”)\"  # @param {type:\"string\"}\n",
    "\n",
    "image = \"captured_image.jpg\"\n",
    "# Load and resize image\n",
    "im = Image.open(io.BytesIO(open(image, \"rb\").read()))\n",
    "im.thumbnail([1024,1024], Image.Resampling.LANCZOS)\n",
    "\n",
    "# Run model to find bounding boxes\n",
    "response = client.models.generate_content(\n",
    "    model=model_name,\n",
    "    contents=[prompt, im],\n",
    "    config = types.GenerateContentConfig(\n",
    "        system_instruction=bounding_box_system_instructions,\n",
    "        temperature=0.5,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Check output\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 480)\n",
      "Image saved as output_image.jpg\n"
     ]
    }
   ],
   "source": [
    "plot_bounding_boxes(im, response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBOT_IP: 192.168.1.155, VERSION: v2.2.0, PROTOCOL: V1, DETAIL: 6,9,LI1006,DL1000,v2.2.0, TYPE1300: [0, 0]\n",
      "change protocol identifier to 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from xarm.wrapper import XArmAPI\n",
    "\n",
    "\n",
    "arm = XArmAPI('192.168.1.155')\n",
    "arm.motion_enable(enable=True)\n",
    "arm.set_mode(0)\n",
    "arm.set_state(0)\n",
    "arm.connect()\n",
    "arm.move_gohome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_boxes = parse_json(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'box_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m c2 = (abs_y1 + abs_y2) / \u001b[32m2\u001b[39m\n\u001b[32m     19\u001b[39m c1_robot, c2_robot = pixel_to_robot(c1, c2, homography_matrix)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mpick_up_and_drop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc1_robot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2_robot\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mpick_up_and_drop\u001b[39m\u001b[34m(x_robot, y_robot)\u001b[39m\n\u001b[32m      7\u001b[39m arm.set_position(x_robot, y_robot, \u001b[32m16.5\u001b[39m, wait=\u001b[38;5;28;01mTrue\u001b[39;00m)  \n\u001b[32m      8\u001b[39m arm.set_position(x_robot, y_robot, \u001b[32m50\u001b[39m, wait=\u001b[38;5;28;01mTrue\u001b[39;00m)  \n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m arm.set_position(\u001b[43mbox_x\u001b[49m, box_y, \u001b[32m200\u001b[39m)\n\u001b[32m     10\u001b[39m arm.set_position(box_x, box_y, \u001b[32m100\u001b[39m)\n\u001b[32m     11\u001b[39m arm.set_suction_cup(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'box_x' is not defined"
     ]
    }
   ],
   "source": [
    "for i, bounding_box in enumerate(json.loads(bounding_boxes)):\n",
    "\n",
    "    width, height = im.size\n",
    "    # Convert normalized coordinates to absolute coordinates\n",
    "    abs_y1 = int(bounding_box[\"box_2d\"][0]/1000 * height)\n",
    "    abs_x1 = int(bounding_box[\"box_2d\"][1]/1000 * width)\n",
    "    abs_y2 = int(bounding_box[\"box_2d\"][2]/1000 * height)\n",
    "    abs_x2 = int(bounding_box[\"box_2d\"][3]/1000 * width)\n",
    "\n",
    "    if abs_x1 > abs_x2:\n",
    "        abs_x1, abs_x2 = abs_x2, abs_x1\n",
    "\n",
    "    if abs_y1 > abs_y2:\n",
    "        abs_y1, abs_y2 = abs_y2, abs_y\n",
    "    \n",
    "    c1 = (abs_x1 + abs_x2) / 2\n",
    "    c2 = (abs_y1 + abs_y2) / 2\n",
    "\n",
    "    c1_robot, c2_robot = pixel_to_robot(c1, c2, homography_matrix)\n",
    "    pick_up_and_drop(c1_robot, c2_robot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate gemini api and the pickup and drop sub-routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: \n",
    "# 1. Get the bounding box\n",
    "# 2. Get the label\n",
    "# 3. Get the center of the bounding box\n",
    "# 4. Get the pixel coordinates of the center of the bounding box\n",
    "# 5. Convert the pixel coordinates to robot coordinates\n",
    "# 6. Move the robot to the robot coordinates\n",
    "# 7. Pick up the object\n",
    "# 8. Move the robot to the box\n",
    "# 9. Drop the object\n",
    "# 10. Repeat for all objects\n",
    "import numpy as np\n",
    "import cv2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
