{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel coordinates extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle click event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(0)\n",
    "pixel_coordinates = []\n",
    "\n",
    "# Track mouse clicks\n",
    "def click_event(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        pixel_coordinates.append((x, y))\n",
    "        print(f\"Clicked at: ({x}, {y})\")\n",
    "\n",
    "cv2.namedWindow(\"Pixel Coordinates\")\n",
    "cv2.setMouseCallback(\"Pixel Coordinates\", click_event)\n",
    "\n",
    "# Display video feed\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Pixel Coordinates\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate homgeneous transform matrix for transformation from camera's frame of reference to end effector frame of reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homography Matrix: [[-1.21974072e+00 -4.47658707e-02  6.45627843e+02]\n",
      " [-9.80664918e-02  1.32604981e+00 -1.20234612e+02]\n",
      " [ 1.60982444e-04  2.56874582e-04  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Clicked at: (239, 115)\n",
    "# Clicked at: (376, 126)\n",
    "# Clicked at: (303, 189)a\n",
    "# Clicked at: (285, 199)\n",
    "# Clicked at: (226, 250)\n",
    "# Clicked at: (367, 260)\n",
    "\n",
    "pixel_coordinates = [[238, 115], [376, 125], [300, 190], [286, 200], [226, 247], [367, 261]]\n",
    "robot_coordinates = [[328.1, 8.5], [165.6, 8.5], [246.5, 90.9], [263.8, 107.5], [325.6, 168.8], [165.6, 168.8]]\n",
    "pixel_points = np.array(pixel_coordinates, dtype=np.float32)\n",
    "robot_points = np.array(robot_coordinates, dtype=np.float32)\n",
    "\n",
    "homography_matrix, _ = cv2.findHomography(pixel_points, robot_points)\n",
    "print(\"Homography Matrix:\", homography_matrix)\n",
    "\n",
    "def pixel_to_robot(x, y, matrix):\n",
    "    pixel = np.array([x, y, 1]).reshape(3, 1)\n",
    "    robot_coords = np.dot(matrix, pixel)\n",
    "    robot_coords /= robot_coords[2]  \n",
    "    return robot_coords[0][0], robot_coords[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box coordinates from camera reference to end effector reference frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = pixel_to_robot(280, 399, homography_matrix)\n",
    "box_x, box_y = box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBOT_IP: 192.168.1.155, VERSION: v2.2.0, PROTOCOL: V1, DETAIL: 6,9,LI1006,DL1000,v2.2.0, TYPE1300: [0, 0]\n",
      "change protocol identifier to 3\n",
      "ControllerError, code: 2\n",
      "[motion_enable], xArm is not ready to move\n",
      "[set_state], xArm is ready to move\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ControllerError had clean\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ControllerError, code: 2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from xarm.wrapper import XArmAPI\n",
    "\n",
    "\n",
    "arm = XArmAPI('192.168.1.155')\n",
    "arm.motion_enable(enable=True)\n",
    "arm.set_mode(0)\n",
    "arm.set_state(0)\n",
    "arm.connect()\n",
    "arm.move_gohome()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start window listener stream\n",
    "1. Click object to pick\n",
    "2. Transform pixel to end effector coordinate frame (P)\n",
    "3. Move arm to the point (P) with a fixed height\n",
    "4. Pick the object\n",
    "5. Go to dropping destination\n",
    "6. Lower arm and drop the object\n",
    "7. Go back to home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick up and drop sub-routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_coordinates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_up_and_drop(x_robot, y_robot):\n",
    "    arm.set_position(x_robot, y_robot, 70, speed=100)  \n",
    "    arm.set_position(x_robot, y_robot, 27, speed=100)  \n",
    "    arm.set_suction_cup(False)\n",
    "    arm.set_position(box_x, box_y, 200, speed=100)\n",
    "    arm.set_position(box_x, box_y, 100, speed=100)\n",
    "    arm.set_suction_cup(True)\n",
    "    arm.set_position(box_x, box_y, 200, speed=100)\n",
    "    arm.move_gohome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicked at: (365, 260)\n",
      "Moving to: (167.72602544189203, 167.69112189774935)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "cv2.namedWindow(\"Click to Move\")\n",
    "cv2.setMouseCallback(\"Click to Move\", click_event)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imshow(\"Click to Move\", frame)\n",
    "    \n",
    "    if len(pixel_coordinates) > 0:\n",
    "        x_pixel, y_pixel = pixel_coordinates.pop(0)\n",
    "        x_robot, y_robot = pixel_to_robot(x_pixel, y_pixel, homography_matrix)\n",
    "        print(f\"Moving to: ({x_robot}, {y_robot})\")\n",
    "        pick_up_and_drop(x_robot, y_robot)\n",
    "        # arm.set_position(x_robot, y_robot, 70, speed=100)  \n",
    "        # arm.set_position(x_robot, y_robot, 27, speed=100)  \n",
    "        # arm.set_suction_cup(False)\n",
    "        # arm.set_position(box_x, box_y, 200, speed=100)\n",
    "        # arm.set_position(box_x, box_y, 100, speed=100)\n",
    "        # arm.set_suction_cup(True)\n",
    "        # arm.set_position(box_x, box_y, 200, speed=100)\n",
    "        # arm.move_gohome()\n",
    "        \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the bounding box detections:\n",
      "```json\n",
      "[\n",
      "  {\"box_2d\": [434, 392, 490, 507], \"label\": \"cube\"},\n",
      "  {\"box_2d\": [341, 535, 407, 682], \"label\": \"cube\"},\n",
      "  {\"box_2d\": [277, 314, 351, 453], \"label\": \"cube\"},\n",
      "  {\"box_2d\": [426, 117, 492, 257], \"label\": \"cube\"},\n",
      "  {\"box_2d\": [556, 264, 610, 375], \"label\": \"cube\"},\n",
      "  {\"box_2d\": [589, 610, 657, 746], \"label\": \"cube\"},\n",
      "  {\"box_2d\": [471, 757, 534, 903], \"label\": \"cube\"}\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "import os\n",
    "from google import genai\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "prompt = (\n",
    "  \"Detect items, with no more than 20 items. Output a json list where each entry contains the 2D bounding box in box_2d and a text label in label.\"\n",
    ")\n",
    "\n",
    "img_path = \"imgs/WhatsApp Image 2025-03-05 at 16.53.00_17d1376b.jpg\"\n",
    "\n",
    "file_ref = client.files.upload(file=img_path)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "  model=\"gemini-2.0-flash\",\n",
    "  contents=[file_ref, prompt]\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate gemini api and the pickup and drop sub-routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "cv2.namedWindow(\"Click to Move\")\n",
    "cv2.setMouseCallback(\"Click to Move\", click_event)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imshow(\"Click to Move\", frame)\n",
    "\n",
    "    cv2.imwrite(\"imgs/captured_frame.jpg\", frame)\n",
    "        \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini Vision Transformer Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "  {\"box_2d\": [46, 437, 174, 528], \"label\": \"crumpled paper\"},\n",
      "  {\"box_2d\": [443, 435, 517, 493], \"label\": \"crumpled paper\"},\n",
      "  {\"box_2d\": [179, 638, 671, 801], \"label\": \"water bottle\"},\n",
      "  {\"box_2d\": [144, 129, 655, 373], \"label\": \"cardboard box\"},\n",
      "  {\"box_2d\": [426, 485, 815, 638], \"label\": \"cardboard box\"},\n",
      "  {\"box_2d\": [684, 203, 896, 444], \"label\": \"cup\"},\n",
      "  {\"box_2d\": [357, 196, 408, 220], \"label\": \"text\"},\n",
      "  {\"box_2d\": [354, 196, 402, 232], \"label\": \"text\"},\n",
      "  {\"box_2d\": [315, 249, 471, 308], \"label\": \"text\"}\n",
      "]\n",
      "```\n",
      "[{'box_2d': [46, 437, 174, 528], 'label': 'crumpled paper'}, {'box_2d': [443, 435, 517, 493], 'label': 'crumpled paper'}, {'box_2d': [179, 638, 671, 801], 'label': 'water bottle'}, {'box_2d': [144, 129, 655, 373], 'label': 'cardboard box'}, {'box_2d': [426, 485, 815, 638], 'label': 'cardboard box'}, {'box_2d': [684, 203, 896, 444], 'label': 'cup'}, {'box_2d': [357, 196, 408, 220], 'label': 'text'}, {'box_2d': [354, 196, 402, 232], 'label': 'text'}, {'box_2d': [315, 249, 471, 308], 'label': 'text'}]\n",
      "Data stored in detected_items.json\n",
      "Centroids have been written to centroids.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "# GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "GEMINI_API_KEY = \"AIzaSyCwyjIPRVcDmZJUgt_9vq7WUaqQPSX3TN4\"\n",
    "\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "def store_json(data, file_name):\n",
    "    with open(file_name, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(f\"Data stored in {file_name}\")\n",
    "\n",
    "\n",
    "def calculate_centroid(box):\n",
    "    x1, y1, x2, y2 = box  # Unpacking list format\n",
    "    centroid_x = (x1 + x2) / 2\n",
    "    centroid_y = (y1 + y2) / 2\n",
    "    return centroid_x, centroid_y\n",
    "\n",
    "\n",
    "def process_json(input_file, output_file):\n",
    "    with open(input_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    centroids = []\n",
    "    for item in data:\n",
    "        if isinstance(item[\"box_2d\"], list):  # Ensure box_2d is in list format\n",
    "            centroid = calculate_centroid(item[\"box_2d\"])\n",
    "            centroids.append({\"centroid_x\": centroid[0], \"centroid_y\": centroid[1]})\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(centroids, f, indent=4)\n",
    "    \n",
    "    print(f\"Centroids have been written to {output_file}\")\n",
    "\n",
    "def get_api_response(image_path, prompt):\n",
    "    file_ref = client.files.upload(file=image_path)\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=[file_ref, prompt]\n",
    "    )\n",
    "    # remove ```json``` from the response\n",
    "    print(response.text)\n",
    "    response = response.text.replace(\"```json\", \"\")\n",
    "    response = response.replace(\"```\", \"\")\n",
    "    #check if output is json\n",
    "    try:\n",
    "        response = json.loads(response)\n",
    "        return response\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Error: Output is not a valid JSON\")\n",
    "        return e\n",
    "\n",
    "image_path = \"imgs\\img2.jpg\"\n",
    "prompt = (\n",
    "    \"Detect items, with no more than 20 items. Output a JSON where each entry contains the 2D bounding box in 'box_2d' \"\n",
    "    \"and a text label in 'label'. Mainly focus on detecting garbage related materials.\"\n",
    "    \"Ensure the output is a valid JSON without additional text or formatting.\"\n",
    ") \n",
    "\n",
    "detected_objects = get_api_response(image_path, prompt)\n",
    "print(detected_objects)\n",
    "input_json_file = \"detected_items.json\"\n",
    "output_json_file = \"centroids.json\"\n",
    "\n",
    "store_json(detected_objects, input_json_file)\n",
    "\n",
    "process_json(input_json_file, output_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image with centroids saved to image.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "def overlay_centroids(image_path, centroids_file, output_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    with open(centroids_file, 'r') as f:\n",
    "        centroids = json.load(f)\n",
    "    \n",
    "    for centroid in centroids:\n",
    "        x, y = int(round(centroid[\"centroid_x\"])), int(round(centroid[\"centroid_y\"]))\n",
    "        cv2.circle(image, (x, y), radius=5, color=(0, 0, 255), thickness=-1)  # Red dot\n",
    "    \n",
    "    cv2.imwrite(output_path, image)\n",
    "    print(f\"Image with centroids saved to {output_path}\")\n",
    "overlay_centroids(image_path, output_json_file, 'image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_detections(image_path, detections_file, output_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Could not load image from {image_path}\")\n",
    "        return\n",
    "    \n",
    "    height, width, _ = image.shape  # Get the current image dimensions\n",
    "    \n",
    "    with open(detections_file, 'r') as f:\n",
    "        detections = json.load(f)\n",
    "\n",
    "    for detection in detections:\n",
    "        try:\n",
    "            box = detection[\"box_2d\"]\n",
    "            \n",
    "            # Scale bounding box coordinates if they are normalized\n",
    "            x1, y1, x2, y2 = box\n",
    "            if 0 <= x1 <= 1 and 0 <= y1 <= 1:  # If coordinates are normalized\n",
    "                x1 = int(x1 * width)\n",
    "                y1 = int(y1 * height)\n",
    "                x2 = int(x2 * width)\n",
    "                y2 = int(y2 * height)\n",
    "            else:\n",
    "                x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "\n",
    "            label = detection[\"label\"]\n",
    "            centroid_x, centroid_y = calculate_centroid([x1, y1, x2, y2])\n",
    "\n",
    "            # Ensure bounding boxes are within image boundaries\n",
    "            x1, x2 = max(0, min(x1, width)), max(0, min(x2, width))\n",
    "            y1, y2 = max(0, min(y1, height)), max(0, min(y2, height))\n",
    "\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green box\n",
    "\n",
    "            # Draw centroid\n",
    "            if 0 <= centroid_x < width and 0 <= centroid_y < height:\n",
    "                cv2.circle(image, (centroid_x, centroid_y), radius=5, color=(0, 0, 255), thickness=-1)  # Red dot\n",
    "\n",
    "            # Put label text\n",
    "            cv2.putText(image, label, (x1, max(y1 - 10, 0)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error drawing detection {detection}: {e}\")\n",
    "\n",
    "    cv2.imwrite(output_path, image)\n",
    "    print(f\"Image with detections saved to {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont, ImageColor\n",
    "import json\n",
    "\n",
    "additional_colors = [colorname for (colorname, colorcode) in ImageColor.colormap.items()]\n",
    "\n",
    "def parse_json(json_str):\n",
    "    \"\"\"\n",
    "    Parse a JSON string, removing markdown fencing if present.\n",
    "    \n",
    "    Args:\n",
    "        json_str: A JSON string, possibly with markdown fencing.\n",
    "    \n",
    "    Returns:\n",
    "        Clean JSON string without markdown fencing.\n",
    "    \"\"\"\n",
    "    if isinstance(json_str, str):\n",
    "        # Remove markdown fencing if present\n",
    "        json_str = json_str.replace(\"```json\", \"\")\n",
    "        json_str = json_str.replace(\"```\", \"\")\n",
    "        return json_str\n",
    "    elif isinstance(json_str, (dict, list)):\n",
    "        # If it's already a dict or list, convert to string\n",
    "        return json.dumps(json_str)\n",
    "    else:\n",
    "        return str(json_str)\n",
    "\n",
    "def plot_bounding_boxes(im, bounding_boxes):\n",
    "    \"\"\"\n",
    "    Plots bounding boxes on an image with markers for each a name, using PIL, normalized coordinates, and different colors.\n",
    "\n",
    "    Args:\n",
    "        img_path: The path to the image file.\n",
    "        bounding_boxes: A list of bounding boxes containing the name of the object\n",
    "         and their positions in normalized [y1 x1 y2 x2] format.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the image\n",
    "    img = im\n",
    "    width, height = img.size\n",
    "    print(img.size)\n",
    "    # Create a drawing object\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # Define a list of colors\n",
    "    colors = [\n",
    "    'red',\n",
    "    'green',\n",
    "    'blue',\n",
    "    'yellow',\n",
    "    'orange',\n",
    "    ] + additional_colors\n",
    "\n",
    "    # Parsing out the markdown fencing\n",
    "    bounding_boxes = parse_json(bounding_boxes)\n",
    "    print(bounding_boxes)\n",
    "\n",
    "    # Use the default font\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "    # Iterate over the bounding boxes\n",
    "    for i, bounding_box in enumerate(json.loads(bounding_boxes)):\n",
    "      # Select a color from the list\n",
    "      color = colors[i % len(colors)]\n",
    "\n",
    "      # Convert normalized coordinates to absolute coordinates\n",
    "      abs_y1 = int(bounding_box[\"box_2d\"][0]/1000 * height)\n",
    "      abs_x1 = int(bounding_box[\"box_2d\"][1]/1000 * width)\n",
    "      abs_y2 = int(bounding_box[\"box_2d\"][2]/1000 * height)\n",
    "      abs_x2 = int(bounding_box[\"box_2d\"][3]/1000 * width)\n",
    "\n",
    "      if abs_x1 > abs_x2:\n",
    "        abs_x1, abs_x2 = abs_x2, abs_x1\n",
    "\n",
    "      if abs_y1 > abs_y2:\n",
    "        abs_y1, abs_y2 = abs_y2, abs_y1\n",
    "\n",
    "      # Draw the bounding box\n",
    "      draw.rectangle(\n",
    "          ((abs_x1, abs_y1), (abs_x2, abs_y2)), outline=color, width=4\n",
    "      )\n",
    "\n",
    "      # Draw the text\n",
    "      if \"label\" in bounding_box:\n",
    "        draw.text((abs_x1 + 8, abs_y1 + 6), bounding_box[\"label\"], fill=color, font=font)\n",
    "\n",
    "    # Display the image\n",
    "    img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 3000)\n",
      "[{\"box_2d\": [46, 437, 174, 528], \"label\": \"crumpled paper\"}, {\"box_2d\": [443, 435, 517, 493], \"label\": \"crumpled paper\"}, {\"box_2d\": [179, 638, 671, 801], \"label\": \"water bottle\"}, {\"box_2d\": [144, 129, 655, 373], \"label\": \"cardboard box\"}, {\"box_2d\": [426, 485, 815, 638], \"label\": \"cardboard box\"}, {\"box_2d\": [684, 203, 896, 444], \"label\": \"cup\"}, {\"box_2d\": [357, 196, 408, 220], \"label\": \"text\"}, {\"box_2d\": [354, 196, 402, 232], \"label\": \"text\"}, {\"box_2d\": [315, 249, 471, 308], \"label\": \"text\"}]\n"
     ]
    }
   ],
   "source": [
    "#get the detected objects from the output json\n",
    "detected_objects = json.load(open('detected_items.json'))\n",
    "# use plot bounding boxes to plot the bounding boxes\n",
    "plot_bounding_boxes(Image.open('imgs/img2.jpg'), detected_objects)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
