{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting groq\n",
      "  Downloading groq-0.20.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\charu\\anaconda3\\envs\\myenv2\\lib\\site-packages (from groq) (4.6.2)\n",
      "Collecting distro<2,>=1.7.0 (from groq)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\charu\\anaconda3\\envs\\myenv2\\lib\\site-packages (from groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\charu\\anaconda3\\envs\\myenv2\\lib\\site-packages (from groq) (2.10.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\charu\\anaconda3\\envs\\myenv2\\lib\\site-packages (from groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\charu\\anaconda3\\envs\\myenv2\\lib\\site-packages (from groq) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\charu\\anaconda3\\envs\\myenv2\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\charu\\anaconda3\\envs\\myenv2\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\charu\\anaconda3\\envs\\myenv2\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\charu\\anaconda3\\envs\\myenv2\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\charu\\anaconda3\\envs\\myenv2\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\charu\\anaconda3\\envs\\myenv2\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
      "Downloading groq-0.20.0-py3-none-any.whl (124 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: distro, groq\n",
      "Successfully installed distro-1.9.0 groq-0.20.0\n"
     ]
    }
   ],
   "source": [
    "!pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Output stored in output.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import groq\n",
    "import re\n",
    "\n",
    "# Set Groq API Key\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "# Load Waste Data from JSON File\n",
    "with open(\"waste.json\", \"r\") as file:\n",
    "    waste_data = json.load(file)\n",
    "\n",
    "# Function to Create Prompt for AI\n",
    "def create_prompt(waste_info):\n",
    "    chemical_composition = waste_info.get(\"composition\", \"Unknown\")\n",
    "    waste_label = waste_info.get(\"label\", \"General Waste\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    The following waste material has the given chemical composition:\n",
    "    {chemical_composition}\n",
    "    \n",
    "    Waste Label: {waste_label}\n",
    "    \n",
    "    Task:\n",
    "    1. Determine if this waste is recyclable or non-recyclable.\n",
    "    2. Suggest useful products that can be derived from this waste.\n",
    "    \n",
    "    Answer in a structured JSON format.\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "# Function to Extract JSON from AI Response\n",
    "def extract_json(response_text):\n",
    "    json_match = re.search(r\"\\{.*\\}\", response_text, re.DOTALL)  # Extract JSON part\n",
    "    if json_match:\n",
    "        return json_match.group(0)  # Return only the JSON part\n",
    "    return None\n",
    "\n",
    "# Initialize Groq API Client\n",
    "client = groq.Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "# Store AI responses\n",
    "output_data = []\n",
    "\n",
    "for waste in waste_data:\n",
    "    prompt = create_prompt(waste)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama3-8b-8192\",  \n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=300,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "\n",
    "    # Get AI response\n",
    "    ai_response = response.choices[0].message.content\n",
    "\n",
    "    # Extract JSON from AI response\n",
    "    extracted_json = extract_json(ai_response)\n",
    "\n",
    "    if extracted_json:\n",
    "        try:\n",
    "            response_json = json.loads(extracted_json)  # Convert to valid JSON\n",
    "            output_data.append(response_json)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"‚ùå Failed to decode JSON:\", extracted_json)\n",
    "    else:\n",
    "        print(\"‚ùå No valid JSON found in AI response:\", ai_response)\n",
    "\n",
    "# Save AI Output to JSON File\n",
    "with open(\"output.json\", \"w\") as outfile:\n",
    "    json.dump(output_data, outfile, indent=4)\n",
    "\n",
    "print(\"‚úÖ Output stored in output.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Output stored in output.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import groq\n",
    "import re  # Import regex for cleaning JSON response\n",
    "\n",
    "# Set API Key for Groq\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "# Load JSON file\n",
    "with open(\"waste.json\", \"r\") as file:\n",
    "    waste_data = json.load(file)\n",
    "\n",
    "# Function to create prompt\n",
    "def create_prompt(waste_info):\n",
    "    chemical_composition = waste_info.get(\"composition\", \"Unknown\")\n",
    "    waste_label = waste_info.get(\"label\", \"General Waste\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI that strictly outputs only valid JSON. Do not include explanations or extra formatting.\n",
    "    \n",
    "    The following waste material has the given chemical composition:\n",
    "    {chemical_composition}\n",
    "    \n",
    "    Waste Label: {waste_label}\n",
    "    \n",
    "    Task:\n",
    "    1. Determine if this waste is recyclable or non-recyclable.\n",
    "    2. Suggest useful products that can be derived from this waste.\n",
    "    \n",
    "    Respond in a structured JSON format only.\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "# Initialize Groq client\n",
    "client = groq.Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "# List to store responses\n",
    "output_data = []\n",
    "\n",
    "for waste in waste_data:\n",
    "    prompt = create_prompt(waste)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama3-8b-8192\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=300,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "\n",
    "    # Extract AI response\n",
    "    ai_response = response.choices[0].message.content\n",
    "\n",
    "    # üîπ **Fix: Remove Markdown Code Blocks (` ``` `)**\n",
    "    cleaned_json = re.sub(r\"```json\\n(.*?)\\n```\", r\"\\1\", ai_response, flags=re.DOTALL)\n",
    "\n",
    "    # Convert response to JSON\n",
    "    try:\n",
    "        structured_response = json.loads(cleaned_json)\n",
    "        output_data.append(structured_response)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"‚ö†Ô∏è AI response is not valid JSON, storing raw response instead.\")\n",
    "        output_data.append({\"error\": \"Invalid JSON\", \"raw_output\": ai_response})\n",
    "\n",
    "# Save the output to a JSON file\n",
    "with open(\"output.json\", \"w\") as outfile:\n",
    "    json.dump(output_data, outfile, indent=4)\n",
    "\n",
    "print(\"‚úÖ Output stored in output.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
